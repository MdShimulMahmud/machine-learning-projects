{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_PvvFOe1X-m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    hidden_weights = np.random.randn(input_size, hidden_size) * 0.01\n",
        "    hidden_biases = np.zeros((1, hidden_size))\n",
        "    output_weights = np.random.randn(hidden_size, output_size) * 0.01\n",
        "    output_biases = np.zeros((1, output_size))\n",
        "    return hidden_weights, hidden_biases, output_weights, output_biases\n"
      ],
      "metadata": {
        "id": "aIisiXhB1ZHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, hidden_weights, hidden_biases, output_weights, output_biases):\n",
        "    hidden_layer_output = sigmoid(np.dot(X, hidden_weights) + hidden_biases)\n",
        "    output_layer_output = sigmoid(np.dot(hidden_layer_output, output_weights) + output_biases)\n",
        "    return hidden_layer_output, output_layer_output\n"
      ],
      "metadata": {
        "id": "ZP5HD6Fq1c2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, y, hidden_layer_output, output_layer_output,\n",
        "                    hidden_weights, hidden_biases, output_weights, output_biases, learning_rate):\n",
        "    num_samples = X.shape[0]\n",
        "\n",
        "    # Compute the gradients for output layer\n",
        "    output_error = output_layer_output - y.reshape(-1, 1)\n",
        "    output_delta = output_error * sigmoid_derivative(output_layer_output)\n",
        "    output_weights_gradient = np.dot(hidden_layer_output.T, output_delta)\n",
        "    output_biases_gradient = np.sum(output_delta, axis=0, keepdims=True)\n",
        "\n",
        "    # Compute the gradients for hidden layer\n",
        "    hidden_error = np.dot(output_delta, output_weights.T)\n",
        "    hidden_delta = hidden_error * sigmoid_derivative(hidden_layer_output)\n",
        "    hidden_weights_gradient = np.dot(X.T, hidden_delta)\n",
        "    hidden_biases_gradient = np.sum(hidden_delta, axis=0, keepdims=True)\n",
        "\n",
        "    # Update the weights and biases\n",
        "    output_weights -= learning_rate * output_weights_gradient / num_samples\n",
        "    output_biases -= learning_rate * output_biases_gradient / num_samples\n",
        "    hidden_weights -= learning_rate * hidden_weights_gradient / num_samples\n",
        "    hidden_biases -= learning_rate * hidden_biases_gradient / num_samples\n",
        "\n",
        "    return hidden_weights, hidden_biases, output_weights, output_biases\n"
      ],
      "metadata": {
        "id": "UlGGb5xu1rB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, hidden_units, learning_rate, num_epochs):\n",
        "    num_samples, num_features = X.shape\n",
        "    num_classes = np.max(y) + 1\n",
        "\n",
        "    hidden_weights, hidden_biases, output_weights, output_biases = initialize_parameters(num_features, hidden_units, num_classes)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Forward propagation\n",
        "        hidden_layer_output, output_layer_output = forward_propagation(X, hidden_weights, hidden_biases, output_weights, output_biases)\n",
        "\n",
        "        # Backpropagation\n",
        "        hidden_weights, hidden_biases, output_weights, output_biases = backpropagation(X, y, hidden_layer_output, output_layer_output,\n",
        "                                                                                        hidden_weights, hidden_biases, output_weights, output_biases,\n",
        "                                                                                        learning_rate)\n",
        "\n",
        "    return hidden_weights, hidden_biases, output_weights, output_biases\n"
      ],
      "metadata": {
        "id": "jgm13QWw1tAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, hidden_weights, hidden_biases, output_weights, output_biases):\n",
        "    _, output_layer_output = forward_propagation(X, hidden_weights, hidden_biases, output_weights, output_biases)\n",
        "    predictions = np.argmax(output_layer_output, axis=1)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "UzVNcLSt1vPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predictions, actual_labels):\n",
        "    correct_predictions = np.sum(predictions == actual_labels)\n",
        "    total_samples = len(actual_labels)\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "lJAybSIVjlsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a synthetic dataset\n",
        "num_samples = 5000\n",
        "num_features = int(input(\"Enter the number of input features: \"))\n",
        "num_classes = int(input(\"Enter the number of output classes: \"))\n",
        "\n",
        "X = np.random.randn(num_samples, num_features)\n",
        "y = np.random.randint(num_classes, size=num_samples)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(split_ratio * num_samples)\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Train the neural network\n",
        "learning_rate = float(input(\"Learning rate: \"))\n",
        "num_epochs = int(input(\"Total number of epochs: \"))\n",
        "hidden_units = int(input(\"Enter the no. of hidden units: \"))\n",
        "\n",
        "hidden_weights, hidden_biases, output_weights, output_biases = train(X_train, y_train, hidden_units, learning_rate, num_epochs)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = predict(X_test, hidden_weights, hidden_biases, output_weights, output_biases)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = calculate_accuracy(predictions, y_test)\n",
        "print(\"Accuracy:\", accuracy*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uon73uf1x1p",
        "outputId": "508fc287-fb9b-4aa2-f39a-3d0772a03ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of input features: 10\n",
            "Enter the number of output classes: 3\n",
            "Learning rate: 0.01\n",
            "Total number of epochs: 1000\n",
            "Enter the no. of hidden units: 50\n",
            "Accuracy: 32.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-fVlAp-1z4D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}